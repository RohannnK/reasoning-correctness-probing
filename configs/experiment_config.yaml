models:
  base:
    name: "Qwen/Qwen2.5-Math-1.5B"
    short_name: "qwen-base"
  distilled:
    name: "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B"
    short_name: "r1-distill"

dataset:
  name: "gsm8k"
  split: "test"
  config: "main"

generation:
  temperature: 0.6
  max_new_tokens: 2048
  do_sample: true

segmentation:
  transition_keywords:
    - "wait"
    - "alternatively"
    - "let me reconsider"
    - "double-check"
    - "hmm"
    - "actually"
    - "so the answer is"

probes:
  test_size: 0.2
  random_state: 42
  regularization_C: [0.01, 0.1, 1.0, 10.0]
  mlp_hidden_layer_sizes: [256]

sparsity:
  penalty: "l1"
  solver: "saga"
  C_values: [0.01, 0.1, 1.0, 10.0]
  top_k: 50

early_exit:
  thresholds: [0.5, 0.6, 0.7, 0.8, 0.9, 0.95]

paths:
  cot_output_dir: "data/cot"
  chunks_output_dir: "data/chunks"
  hidden_states_dir: "data/hidden_states"
  probes_dir: "results/probes"
  results_dir: "results"
  figures_dir: "results/figures"
